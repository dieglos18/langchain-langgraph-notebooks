{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb1237f",
   "metadata": {},
   "source": [
    "### ðŸŒŒ**LangGraph Conversation Example**\n",
    "\n",
    "In this notebook, we will build an interactive conversation flow using LangGraph and OpenAI's GPT-4.\n",
    "\n",
    "**Objectives:**\n",
    "- Learn how to define a state with LangGraph\n",
    "- Add a Language Model (LLM) as a node in the graph\n",
    "- Implement a Human-in-the-Loop step where the user provides feedback\n",
    "- Define edges to connect nodes and control the flow of conversation\n",
    "- Compile and run the graph to simulate the conversation\n",
    "\n",
    "**Let's get started!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph langchain-openai typing-extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369e3b6",
   "metadata": {},
   "source": [
    "### **1. Defining the State**\n",
    "\n",
    "In LangGraph, the **State** is the container for all data passed between nodes.  \n",
    "Here, we define the state structure with:\n",
    "- `messages`: A list of messages exchanged in the conversation.\n",
    "- `end`: A boolean flag to indicate when to stop the graph.\n",
    "\n",
    "The `State` class is defined using `TypedDict` for type safety and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    end: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a6ec7",
   "metadata": {},
   "source": [
    "### **2. Creating the Graph**\n",
    "\n",
    "A **StateGraph** is the core structure where nodes and edges are defined.  \n",
    "We initialize the graph with our previously defined `State`, which will handle the flow of messages and control the termination of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e6598",
   "metadata": {},
   "source": [
    "### **3. Setting Up the LLM**\n",
    "\n",
    "The **Language Model (LLM)** is responsible for generating responses in the conversation.  \n",
    "Here, we set up `ChatOpenAI` with the `gpt-4o-mini` model. The function `llm_step` uses the LLM to generate a response based on the current state of the conversation.\n",
    "\n",
    "This step is added as a node in the graph, making it part of the flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad914fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def llm_step(state: State):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(\"llm\", llm_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8c641",
   "metadata": {},
   "source": [
    "### **4. Adding Human-in-the-Loop Step**\n",
    "\n",
    "A **Human-in-the-Loop** step allows user feedback to guide the conversation.  \n",
    "Here, we present the LLM's response to the user, who can:\n",
    "- Type feedback, which becomes the next message in the conversation.\n",
    "- Type \"stop\" to end the conversation, setting the `end` flag to `True`.\n",
    "\n",
    "This node is added as part of the graph to involve human feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2097fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_review(state: State):\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    print(f\"\\n LLM says: {last_message}\")\n",
    "    human_input = input(\"Your feedback (type 'stop' to end, or ENTER to continue): \")\n",
    "\n",
    "    if human_input.strip().lower() == \"stop\":\n",
    "        return {\"end\": True}  # Set flag to end\n",
    "    elif human_input.strip():\n",
    "        return {\"messages\": [(\"user\", human_input)]}\n",
    "    else:\n",
    "        return {\"messages\": []}\n",
    "\n",
    "graph_builder.add_node(\"human\", human_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e250e46",
   "metadata": {},
   "source": [
    "### **5. Setting Up Edges**\n",
    "\n",
    "In LangGraph, **edges** define how nodes are connected.  \n",
    "We create two types of edges:\n",
    "- A regular edge from the `llm` node to the `human` node.\n",
    "- Conditional edges based on the `end` flag. If `end` is `True`, the conversation ends; otherwise, it loops back to the `llm` node.\n",
    "\n",
    "We also define an empty `END` node that marks the end of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"llm\", \"human\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"human\",\n",
    "    lambda state: \"END\" if state.get(\"end\") else \"llm\",\n",
    ")\n",
    "graph_builder.add_node(\"END\", lambda state: state)  # Empty end node\n",
    "\n",
    "graph_builder.set_entry_point(\"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57ab3d",
   "metadata": {},
   "source": [
    "### **6. Compiling the Graph**\n",
    "\n",
    "After defining nodes and edges, we **compile** the graph into a runnable structure.  \n",
    "This step ensures that LangGraph knows the exact sequence of operations to perform when the graph is executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e723a93",
   "metadata": {},
   "source": [
    "### **7. Running the Graph**\n",
    "\n",
    "Finally, we **run the graph** by providing an initial user input.  \n",
    "LangGraph will execute the steps, call nodes, update the state, and stream the conversation as it unfolds.  \n",
    "Once the conversation is complete, we display all the messages, showing a full interaction between the user and the AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8634c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Your initial input: \")\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)], \"end\": False},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# Collect conversation steps and output once at the end\n",
    "conversation = []\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        for message in event[\"messages\"]:\n",
    "            # Append conversation with proper format\n",
    "            role = \"Human\" if message.type == \"user\" else \"AI\"\n",
    "            conversation.append(f\"\\n================================ {role} Message =================================\")\n",
    "            conversation.append(message.content)\n",
    "\n",
    "# Display the full conversation at once\n",
    "print(\"\".join(conversation))\n",
    "\n",
    "print(\"\\nâœ… Conversation ended!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
